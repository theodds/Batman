phat_m          <- array(pnorm(pred_m$yhat.test), c(1, num_g, num_m))
phat_m[,,num_m] <- 1
qhat_m          <- apply(phat_m, c(1,2), stick_break)
m_samp          <- sapply(1:num_g, function(i) sample(m_unique, 1, prob = qhat_m[,1,i]))
## compute the mean
xy_1 <- cbind(X_m[rand_x,], m_samp)
xy_2 <- do.call(rbind, lapply(1:num_y, function(i) xy_1))
xy_3 <- cbind(rep(y_unique, each = num_g), xy_2)
xy   <- xy_3
pred_x <- predict(fit_y[[it]], xy)
phat_x <- array(pnorm(pred_x$yhat.test), c(1, num_g, num_y))
phat_x[,,num_y] <- 1
qhat_x <- apply(phat_x, c(1,2), stick_break)
samps <- sapply(1:num_g, function(i) sum(qhat_x[,1,i] * y_unique))
samp_mu[i] <- mean(samps)
samp_sigma[i] <- sd(samps) / sqrt(num_g)
cat("\rFinishing iteration ", i, "\t\t\t")
}
out <- data.frame(estimate = samp_mu, standard_error = samp_sigma)
return(out)
}
## Simulate x
set.seed(840984+8)
omega <- rdirichlet(n = nrow(fit_y_1$fit$varcount), alpha = rep(1,nrow(X_m)))
set.seed(840984+4)
eta_1_1 <- g_comp(treedraws_y_1, Y_surv[trt == 1],
treedraws_m_1, M_surv[trt == 1],
X_m, omega, 1000, 100, 500)
set.seed(840984+5)
eta_1_0 <- g_comp(treedraws_y_1, Y_surv[trt == 1],
treedraws_m_0, M_surv[trt == 0],
X_m, omega, 1000, 100, 500)
set.seed(840984+6)
eta_0_1 <- g_comp(treedraws_y_0, Y_surv[trt == 0],
treedraws_m_1, M_surv[trt == 1],
X_m, omega, 1000, 100, 500)
set.seed(840984+7)
eta_0_0 <- g_comp(treedraws_y_0, Y_surv[trt == 0],
treedraws_m_0, M_surv[trt == 0],
X_m, omega, 1000, 100, 500)
eta_1_1
mean(eta_1_1$estimate) - mean(eta_0_0$estimate)
library(Batman)
library(Rcpp)
library(tidyverse)
library(Matrix)
set.seed(1121)
## Generate data ----
generate_data <- function(N, P, sigma, weibull_power) {
X <- matrix(rnorm(N*P), nrow = N)
true_rate <- exp(sigma * X[,1])
true_scale <- true_rate^(-1/weibull_power)
Y <- rweibull(N, shape = weibull_power, true_scale)
out <- list(X = X,
Y = Y,
true_rate = true_rate,
true_scale = true_scale,
weibull_power = weibull_power)
}
my_data <- generate_data(N = 1000, P = 3, sigma = .5, weibull_power = 1)
my_data$qX <- SoftBart::quantile_normalize_bart(my_data$X)
plot(my_data$Y, my_data$true_rate)
## Default params ----
my_data$W <- my_data$Y
my_data$idx <- 1:length(my_data$Y) - 1
my_data$probs <- Matrix::Matrix(diag(ncol(my_data$X)), sparse = TRUE)
my_data$num_trees <- 50
my_data$scale_lambda <- 1.5 * sd(log(my_data$Y)) / sqrt(my_data$num_trees)
my_data$shape_lambda_0 <- 1
my_data$rate_lambda_0 <- 1
my_data$num_burn <- 5000
my_data$num_thin <- 1
my_data$num_save <- 5000
my_data$do_ard <- TRUE
my_data$update_alpha <- TRUE
## Make Weib ----
weib_forest <- with(my_data, MakeWeib(probs = probs,
num_trees = as.integer(num_trees),
scale_lambda = scale_lambda,
shape_lambda_0 = shape_lambda_0,
rate_lambda_0 = rate_lambda_0,
weibull_power = weibull_power))
burned_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 500))
weib_forest$do_ard()
burned_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 500))
saved_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 1000))
library(Batman)
library(Rcpp)
library(tidyverse)
library(Matrix)
set.seed(1121)
## Generate data ----
generate_data <- function(N, P, sigma, weibull_power) {
X <- matrix(rnorm(N*P), nrow = N)
true_rate <- exp(sigma * X[,1])
true_scale <- true_rate^(-1/weibull_power)
Y <- rweibull(N, shape = weibull_power, true_scale)
out <- list(X = X,
Y = Y,
true_rate = true_rate,
true_scale = true_scale,
weibull_power = weibull_power)
}
my_data <- generate_data(N = 1000, P = 3, sigma = .5, weibull_power = 1)
my_data$qX <- SoftBart::quantile_normalize_bart(my_data$X)
plot(my_data$Y, my_data$true_rate)
## Default params ----
my_data$W <- my_data$Y
my_data$idx <- 1:length(my_data$Y) - 1
my_data$probs <- Matrix::Matrix(diag(ncol(my_data$X)), sparse = TRUE)
my_data$num_trees <- 50
my_data$scale_lambda <- 1.5 * sd(log(my_data$Y)) / sqrt(my_data$num_trees)
my_data$shape_lambda_0 <- 1
my_data$rate_lambda_0 <- 1
my_data$num_burn <- 5000
my_data$num_thin <- 1
my_data$num_save <- 5000
my_data$do_ard <- TRUE
my_data$update_alpha <- TRUE
## Make Weib ----
weib_forest <- with(my_data, MakeWeib(probs = probs,
num_trees = as.integer(num_trees),
scale_lambda = scale_lambda,
shape_lambda_0 = shape_lambda_0,
rate_lambda_0 = rate_lambda_0,
weibull_power = weibull_power))
burned_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 500))
weib_forest$do_ard()
burned_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 500))
saved_samples <- with(my_data, weib_forest$do_gibbs(qX, Y, W, idx, qX, 1000))
plot(log(my_data$true_rate), colMeans(saved_samples))
abline(a=0,b=1)
plot(my_data$true_rate, colMeans(exp(saved_samples)))
abline(a=0,b=1)
plot(1/my_data$true_rate, colMeans(exp(-saved_samples)))
abline(a=0,b=1)
library(LVBart)
#preparing the data
library(rstan)
library(fdrtool)
packs <- c("rstan", "fdrtool", "gtools", "extraDistr", "MASS", "loo")
install.packages(packs)
#preparing the data
library(rstan)
library(fdrtool)
library(orderstats)
library(gtools)
install.packages("orderstats")
library(orderstats)
library(gtools)
library(extraDistr)
library(MASS)
library(loo)
set.seed(1234)
num_rating <- 10000
num_item <- 100
num_user <- 100
item <- rep(1:100, 100)#Total number of items
user <- rep(1:100, each=100, len =10000) # total number of users
num_basis <- 10
#small_eta <- rhalfnorm(n=num_basis, theta=sqrt(pi/2))
#sigma_eta <- diag(small_eta)
eta <- rnorm(n=num_basis, 0, 1)
Sigma_psi <- diag(length(rep(0,num_basis)))
Psi <- mvrnorm(n=num_item, mu=rep(0,num_basis), Sigma_psi)
W_1 = rep(0, num_item) # item specific effect
W_1 <- Psi%*%eta
W <- rep(W_1, num_item)
b_1 <- rep(0, num_item)
b_1 <- rnorm(n=num_item, 0 , 1)
b <- rep(b_1, num_item) # item effect
e <- rlogis(n=num_rating, 0, 1) #random
alpha_1 <- rnorm(n=num_user, 0, 1)
alpha <- rep(alpha_1, each = num_user, len = num_rating) # user specific effect
#sigma_beta <- rhalfnorm(n=1, theta=sqrt(pi/2))
beta_1 <- rnorm(n=num_item, 0 , 1)
beta <- rep(beta_1, num_item) # item effect
num_cat <- 5
num_rubric <- 2
#K = 4 # number of cutpoints
#M = 2 # number of rubrics
increments <- exp(matrix (rnorm(n = num_rubric*(num_cat-1), 0 ,1),num_rubric , (num_cat-1)))
cutpt <- increments
for (i in 1:num_rubric){
cutpt[i,] <- cumsum(increments[i, ])
}
del <- c(rep(1,30),rep(2, 70) )
user_del <- rep(del, each=100, len = 10000)
sum(del==1)# proportion of users in rubric 1
sum(del==2)# proportion of users in rubric 2
mu <- matrix(0 , num_item , num_user)
for (i in 1:num_item){
for (j in 1:num_user){
mu[i, j] = t(alpha_1[j])* beta_1[i] + W_1[i] + b_1[i] + e[100*(i-1)+j]
}
}
cutpt[1,] = data.matrix(c(quantile(mu, 0.2), quantile(mu,0.4),quantile(mu,.6), quantile(mu, 0.8)))
cutpt[2,] = data.matrix(c(quantile(mu, 0.05), quantile(mu,0.2),quantile(mu,.7), quantile(mu, 0.9)))
z <- matrix(0 , 100, 100)
for (i in 1:100){
for (j in 1:100){
theta = cutpt[del[j],]
if (mu[i,j] < theta[1]) {
z[i, j] <- 1
}   else if(theta[1] <= mu[i, j] & mu[i, j] < theta[2]){
z[i, j] <- 2
}   else if(theta[2] <= mu[i, j] & mu[i, j] <theta[3]){
z[i, j] <- 3
}  else if(theta[3] <= mu[i, j] & mu[i, j] <theta[4]){
z[i, j] <- 4
}   else {
z[i, j] <- 5
}
}
}
mu <- as.vector(mu)
z <- as.vector(z)
final <- as.matrix(cbind(z,item, user))
log_sum_exp <- function(x) {
M <- max(x)
return(M + log(sum(exp(x-M))))
}
sim_data <- list(num_cat=as.integer(5),
num_user=as.integer(100),
num_item = as.integer(100),
num_rating = as.integer(10000),
num_basis = 10,
num_rubric = as.integer(5),
user = user,
item = item,
rating = z,
Psi = Psi)
stanmodel_code <- '
data {
int<lower=1> num_cat;
int<lower=1> num_user;
int<lower=1> num_item;
int<lower=1> num_rating;
int<lower=1> num_basis;
int<lower=1> num_rubric;
int<lower=1,upper=num_user> user[num_rating];
int<lower=1,upper=num_item> item[num_rating];
int<lower=1,upper=num_cat> rating[num_rating];
matrix[num_item,num_basis] Psi;
}
parameters {
simplex[num_rubric] omega;
matrix[num_rubric,num_cat-1] increments;
vector[num_user] alpha_1;
vector[num_item] beta_1;
vector[num_basis] eta;
vector[num_item] b;
}
transformed parameters {
vector[num_cat-1] theta[num_rubric];
for(m in 1:num_rubric) {
theta[m][1] = increments[m,1];
for(j in 2:(num_cat-1)) {
theta[m][j] = theta[m][j-1] + exp(increments[m,j]);
}
}
}
model {
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
omega ~ dirichlet(rep_vector(1,num_rubric));
for(m in 1:num_rubric) {
for(j in 1:(num_cat-1)) {
increments[m,j] ~ normal(0,1);
}
}
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
for(i in 1:num_user) {
target += log_sum_exp(ps[i]);
}
}
generated quantities {
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
}'
mod <- stan_model(model_code = stanmodel_code, verbose = TRUE)
fit_vb <- vb(mod, data=sim_data, init=0)
list_of_draws_vb <- extract(fit_vb) #extract the output
#omega
num_rubric = 5
omega_vb <- list_of_draws_vb$omega
omegavb <- rep(0,num_rubric)
for (j in 1:num_rubric){
omegavb[j] <- mean(omega_vb[,j])
}
omegavb
#ps
user_assignment = rep(0, num_user)
user_assignment1 = rep(0, num_user)
stanmodel_code <- '
data {
int<lower=1> num_cat;
int<lower=1> num_user;
int<lower=1> num_item;
int<lower=1> num_rating;
int<lower=1> num_basis;
int<lower=1> num_rubric;
int<lower=1,upper=num_user> user[num_rating];
int<lower=1,upper=num_item> item[num_rating];
int<lower=1,upper=num_cat> rating[num_rating];
matrix[num_item,num_basis] Psi;
}
parameters {
simplex[num_rubric] omega;
matrix[num_rubric,num_cat-1] increments;
vector[num_user] alpha_1;
vector[num_item] beta_1;
vector[num_basis] eta;
vector[num_item] b;
}
transformed parameters {
vector[num_cat-1] theta[num_rubric];
for(m in 1:num_rubric) {
theta[m][1] = increments[m,1];
for(j in 2:(num_cat-1)) {
theta[m][j] = theta[m][j-1] + exp(increments[m,j]);
}
}
}
model {
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
omega ~ dirichlet(rep_vector(1,num_rubric));
for(m in 1:num_rubric) {
for(j in 1:(num_cat-1)) {
increments[m,j] ~ normal(0,1);
}
}
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
for(i in 1:num_user) {
target += log_sum_exp(ps[i]);
}
}
generated quantities {
int assignment[num_user]
{
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
for(i in 1:num_user) {
vector[num_rubric] user_prob;
user_prob = exp(ps[i] - log_sum_exp(ps[i]));
assignment[i] = categorical_rng(user_prob);
}
}
}'
mod <- stan_model(model_code = stanmodel_code, verbose = TRUE)
stanmodel_code <- '
data {
int<lower=1> num_cat;
int<lower=1> num_user;
int<lower=1> num_item;
int<lower=1> num_rating;
int<lower=1> num_basis;
int<lower=1> num_rubric;
int<lower=1,upper=num_user> user[num_rating];
int<lower=1,upper=num_item> item[num_rating];
int<lower=1,upper=num_cat> rating[num_rating];
matrix[num_item,num_basis] Psi;
}
parameters {
simplex[num_rubric] omega;
matrix[num_rubric,num_cat-1] increments;
vector[num_user] alpha_1;
vector[num_item] beta_1;
vector[num_basis] eta;
vector[num_item] b;
}
transformed parameters {
vector[num_cat-1] theta[num_rubric];
for(m in 1:num_rubric) {
theta[m][1] = increments[m,1];
for(j in 2:(num_cat-1)) {
theta[m][j] = theta[m][j-1] + exp(increments[m,j]);
}
}
}
model {
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
omega ~ dirichlet(rep_vector(1,num_rubric));
for(m in 1:num_rubric) {
for(j in 1:(num_cat-1)) {
increments[m,j] ~ normal(0,1);
}
}
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
for(i in 1:num_user) {
target += log_sum_exp(ps[i]);
}
}
generated quantities {
int assignment[num_user];
{
vector[num_item] W;
vector[num_rating] mu;
vector[num_rubric] ps[num_user];
for(i in 1:num_user) {
ps[i] = log(omega);
}
W = Psi * eta;
for(i in 1:num_rating) {
mu[i] = alpha_1[user[i]] * beta_1[item[i]] + W[item[i]] + b[item[i]];
for(m in 1:num_rubric) {
ps[user[i]][m] += ordered_logistic_lpmf(rating[i] | mu[i], theta[m]);
}
}
for(i in 1:num_user) {
vector[num_rubric] user_prob;
user_prob = exp(ps[i] - log_sum_exp(ps[i]));
assignment[i] = categorical_rng(user_prob);
}
}
}'
mod <- stan_model(model_code = stanmodel_code, verbose = TRUE)
fit_vb <- vb(mod, data=sim_data, init=0)
list_of_draws_vb <- extract(fit_vb) #extract the output
names(list_of_draws_vb)
dim(list_of_draws_vb$assignment)
td <- apply(list_of_draws_vb$assignment, 2, function(x) tabulate(x, num_rubric))
head(td)
dim(td)
td <- apply(list_of_draws_vb$assignment, 2, function(x) tabulate(x, num_rubric) / 1000)
td
td <- t(apply(list_of_draws_vb$assignment, 2, function(x) tabulate(x, num_rubric) / 1000))
td
library(Batman)
library(Batman)
library(Batman)
library(Batman)
process_surv <- function(Y, delta, X)
{
o     <- order(Y, 1-delta)
Y     <- Y[o]
delta <- delta[o]
X     <- X[o,]
survs <- Surv(Y, delta)
k <- 1
U <- numeric(length(unique(survs)))
L <- numeric(length(unique(survs)))
L[1] <- 1
for(i in 2:length(survs))
{
if(!identical(survs[i], survs[i-1])) {
U[k] <- i - 1
k <- k + 1
L[k] <- i
}
}
U[length(unique(survs))] <- length(survs)
return(list(o = 1:length(Y) - 1, Y = Y, L = L-1, U = U-1, delta = delta, X = X))
}
proc_dat <- process_surv(my_data$Y, rep(1,N), my_data$X)
library(Batman)
library(Batman)
library(Batman)
